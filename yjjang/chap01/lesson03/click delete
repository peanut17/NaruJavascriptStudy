
Oracle â†’ Kafka â†’ Spark â†’ ClickHouse ì‹¤ì‹œê°„ CDC íŒŒì´í”„ë¼ì¸ì—ì„œ "ì‚­ì œ(Delete)" ì´ë²¤íŠ¸ë¥¼ ClickHouseì— ë°˜ì˜í•˜ë ¤ë©´, Spark Structured Streaming ì½”ë“œì—ì„œ Kafka ë©”ì‹œì§€ì˜ op í•„ë“œë¥¼ ë¶„ì„í•˜ê³ , ì‚­ì œ(op = 'd')ì¸ ê²½ìš° í•´ë‹¹ í‚¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ClickHouseì—ì„œ ì‚­ì œ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.

ClickHouseëŠ” Spark SQLì˜ DELETE ì—°ì‚°ì„ ì§ì ‘ ì§€ì›í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì—, ì¼ë°˜ì ìœ¼ë¡œ ì•„ë˜ ë°©ì‹ ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤:


---

âœ… ì „ì œ ì¡°ê±´

Debezium ë“± CDC ë„êµ¬ë¥¼ í†µí•´ Kafkaë¡œ ì ì¬ ì‹œ ì•„ë˜ì™€ ê°™ì€ JSON êµ¬ì¡°ë¡œ ë©”ì‹œì§€ë¥¼ ë°›ëŠ”ë‹¤ê³  ê°€ì •:

{
  "before": {
    "id": 101,
    "name": "John"
  },
  "op": "d",
  "ts_ms": 1717846220000
}

op = 'c' â†’ insert

op = 'u' â†’ update

op = 'd' â†’ delete

before.id â†’ ì‚­ì œí•  ë ˆì½”ë“œì˜ í‚¤



---

âœ… ClickHouse í…Œì´ë¸”: ReplacingMergeTree ë˜ëŠ” CollapsingMergeTree í™œìš©

ì‚­ì œ ì—°ì‚°ì€ CollapsingMergeTree ì‚¬ìš© ì‹œì—ë§Œ ì˜ë¯¸ê°€ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ Spark ì½”ë“œ ì˜ˆì‹œëŠ” ì´ êµ¬ì¡°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•©ë‹ˆë‹¤.


---

âœ… Spark ì½”ë“œ (Kafka â†’ ClickHouse, Delete ì²˜ë¦¬)

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._

val spark = SparkSession.builder()
  .appName("KafkaToClickHouseCDC")
  .getOrCreate()

// Kafka ë©”ì‹œì§€ ìˆ˜ì‹ 
val kafkaDF = spark.readStream
  .format("kafka")
  .option("kafka.bootstrap.servers", "broker:9092")
  .option("subscribe", "oracle-cdc-topic")
  .load()

// JSON íŒŒì‹±
val parsedDF = kafkaDF.selectExpr("CAST(value AS STRING) as json_str")
  .select(from_json($"json_str", schema).as("data"))
  .selectExpr("data.before.id as id", "data.op as op")

// ì‚­ì œì™€ ì‚½ì… ë¶„ë¦¬
val deletesDF = parsedDF.filter($"op" === "d")
  .withColumn("sign", lit(-1))
  .select($"id", $"sign")  // í•„ìš”í•œ í‚¤ ì»¬ëŸ¼ë§Œ

val insertsDF = parsedDF.filter($"op" === "c" || $"op" === "u")
  .withColumn("sign", lit(1))
  .select($"id", $"sign")  // ì—¬ê¸°ì— ë‹¤ë¥¸ ì»¬ëŸ¼ë„ ì¶”ê°€ ê°€ëŠ¥

val finalDF = deletesDF.union(insertsDF)

// ClickHouseë¡œ ì ì¬
finalDF.writeStream
  .foreachBatch { (batchDF, batchId) =>
    batchDF.write
      .format("jdbc")
      .option("url", "jdbc:clickhouse://your-host:8123/default")
      .option("driver", "com.clickhouse.jdbc.ClickHouseDriver")
      .option("dbtable", "your_table")
      .option("user", "default")
      .option("password", "")
      .mode("append")
      .save()
  }
  .start()
  .awaitTermination()


---

âœ… ClickHouse í…Œì´ë¸” ì˜ˆì‹œ (CollapsingMergeTree)

CREATE TABLE your_table
(
  id UInt64,
  sign Int8
) ENGINE = CollapsingMergeTree(sign)
ORDER BY id;

sign = 1 â†’ insert/update

sign = -1 â†’ delete

ì´í›„ OPTIMIZE TABLE your_table FINAL; ë˜ëŠ” ì£¼ê¸°ì ì¸ TTL ë° ë°±ê·¸ë¼ìš´ë“œ ë¨¸ì§€ë¡œ ë¬¼ë¦¬ì  ì‚­ì œë¨



---

ğŸ” ì°¸ê³ : ReplacingMergeTreeë¡œ ì‚­ì œ ì²˜ë¦¬í•˜ë ¤ë©´?

ì‚­ì œëŠ” ì§ì ‘ ë°˜ì˜ë˜ì§€ ì•ŠìŒ. signì„ ì¨ì„œ ë…¼ë¦¬ì  ì‚­ì œ ì²˜ë¦¬ í›„ ë¨¸ì§€ ì‹œ ì œì™¸í•˜ëŠ” ë°©ì‹ í•„ìš”.


---

í•„ìš”í•˜ë‹¤ë©´ upsertì™€ deleteë¥¼ í•¨ê»˜ ë‹¤ë£¨ëŠ” ë³µí•© ì˜ˆì‹œ ì½”ë“œë„ ë§Œë“¤ì–´ë“œë¦´ ìˆ˜ ìˆì–´ìš”. ì‚¬ìš© ì¤‘ì¸ í…Œì´ë¸” ì—”ì§„ì´ë‚˜ CDC ë©”ì‹œì§€ í˜•ì‹(JSON êµ¬ì¡° ì˜ˆì‹œ)ë„ ì•Œë ¤ì£¼ì‹œë©´ ë” ë§ì¶¤ ì½”ë“œë¡œ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.






ì¢‹ìŠµë‹ˆë‹¤. Oracle â†’ Kafka â†’ Spark â†’ ClickHouse CDC íŒŒì´í”„ë¼ì¸ì—ì„œ upsert + deleteë¥¼ í•¨ê»˜ ì²˜ë¦¬í•˜ëŠ” ë³µí•© ì˜ˆì‹œë¥¼ ì•„ë˜ì— ì •ë¦¬í•´ ë“œë¦½ë‹ˆë‹¤. ì´ ì˜ˆì‹œëŠ” **Debezium ìŠ¤íƒ€ì¼ Kafka ë©”ì‹œì§€(JSON)**ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•˜ê³ , ClickHouseëŠ” CollapsingMergeTreeë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚­ì œë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.


---

âœ… ì „ì œ

Kafka ë©”ì‹œì§€ í¬ë§· (Debezium ê¸°ì¤€):


{
  "before": { "id": 1, "name": "John" },
  "after": { "id": 1, "name": "Johnny" },
  "op": "u"
}

op = 'c': create

op = 'u': update

op = 'd': delete

op = 'r': snapshot (í•„ìš” ì‹œ í•„í„°ë§)



---

âœ… ClickHouse í…Œì´ë¸” (CollapsingMergeTree)

CREATE TABLE user_data
(
  id UInt64,
  name String,
  sign Int8
) ENGINE = CollapsingMergeTree(sign)
ORDER BY id;


---

âœ… Spark Structured Streaming ì½”ë“œ (Scala ê¸°ì¤€)

import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._
import org.apache.spark.sql.SparkSession

val spark = SparkSession.builder()
  .appName("CDC Kafka to ClickHouse")
  .getOrCreate()

// Kafka ë©”ì‹œì§€ ìˆ˜ì‹ 
val kafkaDF = spark.readStream
  .format("kafka")
  .option("kafka.bootstrap.servers", "your-kafka:9092")
  .option("subscribe", "oracle-cdc-topic")
  .option("startingOffsets", "latest")
  .load()

// Debezium ë©”ì‹œì§€ ìŠ¤í‚¤ë§ˆ
val debeziumSchema = new StructType()
  .add("before", new StructType()
    .add("id", LongType)
    .add("name", StringType))
  .add("after", new StructType()
    .add("id", LongType)
    .add("name", StringType))
  .add("op", StringType)

// JSON íŒŒì‹±
val parsedDF = kafkaDF.selectExpr("CAST(value AS STRING) as json")
  .select(from_json(col("json"), debeziumSchema).as("data"))
  .select("data.before", "data.after", "data.op")

// Insert / Update ì²˜ë¦¬ (op = 'c' or 'u')
val upsertDF = parsedDF
  .filter(col("op").isin("c", "u"))
  .select(col("after.id").as("id"), col("after.name").as("name"))
  .withColumn("sign", lit(1))

// Delete ì²˜ë¦¬ (op = 'd')
val deleteDF = parsedDF
  .filter(col("op") === "d")
  .select(col("before.id").as("id"), col("before.name").as("name")) // nameì€ ê·¸ëŒ€ë¡œ
  .withColumn("sign", lit(-1))

// ìµœì¢… í†µí•© DF
val finalDF = upsertDF.union(deleteDF)

// ClickHouse ì ì¬
finalDF.writeStream
  .foreachBatch { (batchDF, batchId) =>
    batchDF.write
      .format("jdbc")
      .option("url", "jdbc:clickhouse://clickhouse-host:8123/default")
      .option("driver", "com.clickhouse.jdbc.ClickHouseDriver")
      .option("dbtable", "user_data")
      .option("user", "default")
      .option("password", "")
      .mode("append")
      .save()
  }
  .outputMode("append")
  .start()
  .awaitTermination()


---

âœ… ì£¼ì˜í•  ì 

CollapsingMergeTreeëŠ” ì‹¤ì œ ì‚­ì œëŠ” ë¨¸ì§€ ì‹œì ì— ë°œìƒí•˜ë¯€ë¡œ, ì£¼ê¸°ì ìœ¼ë¡œ OPTIMIZE TABLE user_data FINALì„ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.

ì¤‘ë³µ ë ˆì½”ë“œê°€ ìˆì„ ê²½ìš°, id ì™¸ì—ë„ updated_at ë“±ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ê±°ë‚˜ ReplacingMergeTreeì™€ í˜¼í•©í•˜ì—¬ ì»¤ìŠ¤í…€ ë¡œì§ êµ¬ì„± ê°€ëŠ¥

Kafka ë©”ì‹œì§€ í¬ê¸°ê°€ í¬ê±°ë‚˜ ì§€ì—° ì´ìŠˆê°€ ìˆìœ¼ë©´ watermarkì™€ checkpoint ì¡°ì • í•„ìš”



---

â“ì¶”ê°€ êµ¬ì„± ê°€ëŠ¥:

Java ê¸°ë°˜ Spark ì½”ë“œ ì˜ˆì‹œ ì œê³µ

íŒŒì´í”„ë¼ì¸ì— Retry/Failover ë¡œì§ ì¶”ê°€

Kafka topicë³„ ë¼ìš°íŒ… ì²˜ë¦¬

ë³€ê²½ëœ í•„ë“œë§Œ ë³„ë„ ì¶”ì í•˜ê¸° ìœ„í•œ Delta ë¡œê·¸ êµ¬ì„±


í•„ìš” ì‹œ ë§ì”€ ì£¼ì„¸ìš”.

