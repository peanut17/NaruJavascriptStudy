
원인부터 정리할게요.
DynamicQueryHandler code 210: DB::NetException: I/O error: Broken pipe, while writing to socket 는 서버가 결과를 보내는 중에 상대(클라이언트/프록시)가 연결을 끊었을 때 나는 전형적인 네트워크 오류입니다. (210은 네트워크 계열 에러코드) 보통 아래 상황에서 재현됩니다.

1. 클라이언트 타임아웃/취소



Spark 태스크 재시작·취소, 드라이버/익스큐터 readTimeout 초과, 애플리케이션이 커넥션 풀에서 소켓을 조기 종료.

Python clickhouse-driver/JDBC/HTTP 클라이언트의 소켓 타임아웃이 짧음.


2. 프록시/로드밸런서가 연결을 닫음



Nginx/ALB 등 앞단 프록시의 proxy_read_timeout, keepalive_timeout 이 짧아서 대용량/장시간 쿼리에서 끊김.

HTTP keep-alive 재사용 중 유휴 시간이 길어 연결이 정리됨.


3. 대용량 결과 전송 중 속도 불일치



클라이언트 소비 속도가 느리거나 GC 등으로 중단 → 서버가 쓰기 시도하다 Broken pipe.

너무 큰 블록 사이즈로 한 번에 밀어내며 지연/타임아웃 유발.



---

바로 해볼 진단 체크리스트

A. ClickHouse 쿼리로그에서 원인 추적

-- 210 오류가 난 쿼리와 클라이언트/UA/주소를 확인
SELECT
  event_time, query_id, initial_user, client_name, http_user_agent, address,
  type, exception, error_code, query
FROM system.query_log
WHERE type = 'Exception' AND error_code = 210
ORDER BY event_time DESC
LIMIT 100;

같은 query_id 가 system.processes/system.query_log 에서 취소(Cancelled) 흔적이 있는지 같이 봐주세요.


B. 서버 로그 동시간대 확인

clickhouse-server.log 에 Broken pipe 직전의 네트워크/HTTP/TCP 관련 메시지, 프록시에서 온 접속인지(헤더·User-Agent) 확인.


C. 경로 점검

애플리케이션 → (프록시/Nginx/ALB?) → ClickHouse(8123/9000) 경로인지 도식화하고, 직결(TCP 9000) 과 HTTP 8123 경유를 분리 테스트.



---

원인별 해결 가이드

1) 클라이언트( Spark / Python / JDBC ) 타임아웃 상향 & 배치 조정

Spark (JDBC/HTTP 커넥터 사용 시)

드라이버/익스큐터 소켓 타임아웃을 넉넉히:

spark.executor.heartbeatInterval=60s

spark.network.timeout=600s

JDBC 옵션(사용 중인 커넥터에 맞게): socket_timeout=600000, connect_timeout=10000, max_execution_time(CH 세팅) 등.


대결과 세트 쿼리는 결과를 나눠 받기:

필요 컬럼만 선택, LIMIT ... OFFSET이나 날짜/샤드 단위로 슬라이싱, max_block_size(클라이언트/서버)로 블록 크기 축소.



Python clickhouse-driver (당신이 CDC에 쓰는 경우가 많았습니다)

from clickhouse_driver import Client
client = Client(
    host='your_ch_host',
    port=9000,               # 가능하면 TCP 사용
    user='xxx', password='xxx', database='xxx',
    send_receive_timeout=600,  # 초
    connect_timeout=10,
    compression=True
)

소비 측 로직(결과를 읽는 코드)이 꾸준히 읽도록 하고, 대량 결과는 스트리밍/청크 처리.


2) 프록시/로드밸런서 타임아웃 확장 또는 우회

가능하면 장시간/대용량 쿼리는 HTTP(8123) 대신 TCP(9000) 네이티브 프로토콜 직결이 안정적입니다.

Nginx 예시(앞단에 있을 때)

proxy_read_timeout  600s;
proxy_send_timeout  600s;
proxy_connect_timeout 60s;
proxy_request_buffering off;
proxy_buffering off;
keepalive_timeout  75s;
keepalive_requests 1000;
# HTTP/1.1 유지
proxy_http_version 1.1;

ALB/ELB, API Gateway 등을 쓴다면 Idle timeout/Read timeout 을 10~15분 이상으로.


3) 전송 블록/페치 사이즈 튜닝 (전송 병목 완화)

서버 측: 필요 시 프로필에서 max_block_size(기본 65k rows 근처) 조금 축소하여 전송 주기를 짧게.

클라이언트 측도 fetch/rowPacket 크기를 너무 크게 잡지 않기.

HTTP 사용 시 압축 사용(enable_http_compression=1, 클라이언트도 gzip)으로 전송 시간 단축.


4) “연결 유지” 안정화

중간 장비가 많다면 OS 레벨 TCP keepalive 활성화(서버/클라이언트 모두):

net.ipv4.tcp_keepalive_time, tcp_keepalive_intvl, tcp_keepalive_probes 완화.


HTTP 경유 시 진행 상황 신호 보내기(대용량 쿼리):

HTTP 클라이언트라면 프로그레스 헤더 수신 옵션을 켜서 유휴 구간을 줄여줍니다(드라이버별 지원 여부 상이).




---

운영 팁 (당장 효과 보는 것들)

1. 에러가 나는 대표 쿼리 하나 골라서

Nginx/ALB 우회해 TCP 9000 직결로 실행 → 에러가 사라지면 프록시 타임아웃 문제입니다.



2. Spark 리드/라이트 타임아웃 을 10분 정도로 상향하고, 쿼리 결과를 날짜/파티션으로 슬라이스.


3. Python/Spark 커넥터의 소켓 타임아웃/페치 사이즈/압축 설정을 위 값으로 일괄 적용.


4. system.query_log로 어떤 클라이언트/경로에서만 210이 나는지 패턴을 확인.




---

필요하시면 지금 사용 중인 접속 방식(HTTP/JDBC/TCP) 과 중간 프록시 유무, 그리고 210이 주로 발생하는 쿼리 유형(대용량 SELECT? 대량 INSERT 후 검증 SELECT?) 을 알려주세요. 그 정보 기준으로 Spark/JDBC 옵션과 Nginx(LB) 설정을 당신 환경에 맞게 딱 맞춰 드릴게요.

