
Kafkaì˜ "test-topic" ë°ì´í„°ë¥¼ PySparkë¥¼ ì‚¬ìš©í•˜ì—¬ ClickHouseë¡œ ì ì¬í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•´ ì¤„ê²Œìš”.

êµ¬í˜„ íë¦„

1. Kafkaì—ì„œ ë°ì´í„° ì½ê¸°: PySparkì˜ readStreamì„ ì‚¬ìš©í•˜ì—¬ Kafka ë°ì´í„°ë¥¼ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ê°€ì ¸ì˜´.


2. JSON íŒŒì‹±: Kafkaì˜ ë©”ì‹œì§€ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜.


3. ClickHouseë¡œ ì ì¬: PySpark DataFrameì„ ClickHouse í…Œì´ë¸”ë¡œ ì ì¬.



ì‚¬ì „ ì¤€ë¹„

ClickHouse JDBC ë“œë¼ì´ë²„ ë‹¤ìš´ë¡œë“œ

wget https://repo1.maven.org/maven2/cc/blynk/clickhouse/clickhouse-jdbc/0.3.2/clickhouse-jdbc-0.3.2.jar -P $SPARK_HOME/jars/

PySpark ì‹¤í–‰ ì‹œ ì¶”ê°€ ì˜µì…˜ ì‚¬ìš©

spark-submit --jars $SPARK_HOME/jars/clickhouse-jdbc-0.3.2.jar script.py



---

Kafka â†’ PySpark â†’ ClickHouse ì½”ë“œ

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, from_json
from pyspark.sql.types import StructType, StringType, IntegerType
from pyspark.sql.streaming import DataStreamWriter

# SparkSession ìƒì„±
spark = SparkSession.builder \
    .appName("KafkaToClickHouse") \
    .config("spark.jars", "/path/to/clickhouse-jdbc-0.3.2.jar") \
    .getOrCreate()

# Kafkaì—ì„œ ë°ì´í„° ì½ê¸°
kafka_bootstrap_servers = "localhost:9092"
kafka_topic = "test-topic"

raw_stream_df = spark.readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", kafka_bootstrap_servers) \
    .option("subscribe", kafka_topic) \
    .option("startingOffsets", "earliest") \
    .load()

# JSON íŒŒì‹±ì„ ìœ„í•œ ìŠ¤í‚¤ë§ˆ ì •ì˜
schema = StructType() \
    .add("id", IntegerType()) \
    .add("name", StringType()) \
    .add("value", IntegerType())

# Kafka ë©”ì‹œì§€ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜
parsed_df = raw_stream_df.selectExpr("CAST(value AS STRING)") \
    .select(from_json(col("value"), schema).alias("data")) \
    .select("data.*")

# ClickHouse ì—°ê²° ì •ë³´
clickhouse_url = "jdbc:clickhouse://localhost:8123/default"
clickhouse_table = "test_table"
clickhouse_properties = {
    "driver": "cc.blynk.clickhouse.ClickHouseDriver",
    "user": "default",
    "password": ""
}

# ClickHouseë¡œ ë°ì´í„° ì ì¬ (Batch ë°©ì‹)
def write_to_clickhouse(batch_df, batch_id):
    batch_df.write \
        .format("jdbc") \
        .option("url", clickhouse_url) \
        .option("dbtable", clickhouse_table) \
        .option("user", clickhouse_properties["user"]) \
        .option("password", clickhouse_properties["password"]) \
        .option("driver", clickhouse_properties["driver"]) \
        .mode("append") \
        .save()

# ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„°ë¥¼ ClickHouseë¡œ ì“°ê¸°
query = parsed_df.writeStream \
    .foreachBatch(write_to_clickhouse) \
    .outputMode("update") \
    .start()

query.awaitTermination()


---

ClickHouse í…Œì´ë¸” ìƒì„± ì˜ˆì‹œ

PySparkì—ì„œ ì ì¬í•˜ë ¤ëŠ” ClickHouse í…Œì´ë¸”ì„ ë¯¸ë¦¬ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.

CREATE TABLE test_table (
    id Int32,
    name String,
    value Int32
) ENGINE = MergeTree()
ORDER BY id;

ì„¤ëª…

1. Kafkaì—ì„œ ë°ì´í„°ë¥¼ ì½ìŒ (readStream)


2. JSON íŒŒì‹± (from_json)


3. Batch ë°©ì‹ìœ¼ë¡œ ClickHouse ì ì¬ (foreachBatch)


4. ìŠ¤íŠ¸ë¦¬ë° ì§€ì† ì‹¤í–‰ (query.awaitTermination())



ì´ë ‡ê²Œ í•˜ë©´ Kafkaì˜ test-topic ë°ì´í„°ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ClickHouseë¡œ ì ì¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸš€

